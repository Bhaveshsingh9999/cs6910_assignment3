# -*- coding: utf-8 -*-
"""finaltrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DpszG8oPLKmH9pEltFTJkYB2orDGA1yV
"""

# -*- coding: utf-8 -*-
"""finalcodedonetrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bvska2i_NGA9SQK7qG0l3bDpJs7dMQ11
"""

import pandas as pd
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import wandb
import random
import argparse

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#wandb login key 
wandb.login(key='44fa96b263794ea519fb29399eb6b8f469eb934b')

#########################for argpass parameters #######################################################################

# parser=argparse.ArgumentParser()

# parser.add_argument("-wp","--wandb_project",type=str, default="DLSeqtoseq")
# parser.add_argument("-we","--wandb_entity", type=str, default="singhbhavesh999")
# parser.add_argument("-e","--epochs",type=int,default=15)
# parser.add_argument("-b","--batch_size",type=int,default=128)
# parser.add_argument("-emb","--embedding_size",type=int,default=512)
# parser.add_argument("-ct","--cell_type",choices=["RNN", "LSTM", "GRU"],default="GRU")
# parser.add_argument("-attn","--attention",type=bool,default = True)
# parser.add_argument("-sz","--hidden_size",type=int,default=512)
# parser.add_argument("-nhl","--num_layers",type=int,default=2)
# parser.add_argument("-dpe","--dropout_encoder",type=float, default=0.4)
# parser.add_argument("-dpd","--dropout_decoder",type=float, default=0.3)
# parser.add_argument("-bd","--bidirectional",type=bool,default = True)



# args=parser.parse_args()

# currdir = os.getcwd()
# train_dataset_path=os.path.join(currdir,"aksharantar_sampled","hin","hin_train.csv")
# test_dataset_path=os.path.join(currdir,"aksharantar_sampled","hin","hin_test.csv")
# valid_dataset_path=os.path.join(currdir,"aksharantar_sampled","hin","hin_valid.csv")

# print(train_dataset_path)

# train_dataset = pd.read_csv(train_dataset_path,header=None)
# test_dataset=pd.read_csv(test_dataset_path,header=None)
# valid_dataset=pd.read_csv(valid_dataset_path,header=None)

##########################################################################################################

train_dataset = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv',header=None)
test_dataset=pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',header=None)
valid_dataset=pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv' ,header=None)

lang2_ = 'HINDI'
SOW_token = 0 #<
EOW_token = 1 #>
UNK_token = 2 #_
PAD_token = 3 #@

sweep_config = {
  
  "metric": {
      "name":"validation_accuracy",
      "goal": "maximize"
  },
  "method": "bayes",
  "parameters": {
        "bidirectional": {
            "values": [True,False]
        },
        "embedding_size": {
            "values": [512, 256, 64, 32]
        },
        "hidden_layer": {
            "values": [512, 256, 128]
        },
        "epochs": {
            "values": [10,15]
        },
        "cell_type": {
            "values": ["RNN","GRU","LSTM"]
        },
        "num_layers": {
            "values": [3, 2, 1]
        },
        "dropout_encoder": {
            "values": [0.2, 0.3, 0.4]
        },
        "dropout_decoder": {
            "values": [0.2, 0.3, 0.4]
        },
        "batch_size": {
            "values": [256, 128, 64]
        }
    }
}
sweep_id = wandb.sweep(sweep_config, project="DLSeqtoseq")

#to make a dictionary of char->index  and index->char which will we used to conver to word to tensor and tensor to word 

class make_dict:
    def __init__(self,name):
        self.name=name
        self.chartoindex={}
        self.indextochar={SOW_token: "<", EOW_token: ">",UNK_token:"_",PAD_token:'@'}
        self.n_chars=4
    
    def addchar(self,word):
        for char in word:
            if char not in self.chartoindex:
                self.chartoindex[char]=self.n_chars
                self.indextochar[self.n_chars]=char
                self.n_chars+=1

#the dataset that is provided to the function it create the input and output dictionary of that dataset so train dataset is to 
#be passed it return the dictionary hindi and english and both the column in list format 
def Input_Output_train(df):
    #convert the dataframe to list 
    input_word=df.iloc[:,0].tolist()
    output_word=df.iloc[:,1].tolist()
    input_lang=make_dict('ENG')
    output_lang=make_dict('HINDI')
    
    # to make a dictionary of characters for the input language 
    for word in input_word:
        input_lang.addchar(word)
   # to make a dictionary of characters for teh output language 
    for word in output_word:
        output_lang.addchar(word)
    return input_lang,output_lang,input_word,output_word



#use to get max length+1 ,+1 is for EOW(end of word)for the input words datset provided as input to the function 
def getlength_x(df):
    input_list = df.iloc[:,0].tolist()
    input_list_length=[]
    for word in input_list:
        input_list_length.append(len(word))
    
    input_max_length=max(input_list_length)
    return input_max_length+1

#use to get max length+1 , +1 is for EOW for the output words datset provided as input to the function 
def getlength_y(df):
    output_list =df.iloc[:,1].tolist()
    output_list_length=[]
    for word in output_list:
        output_list_length.append(len(word))
    output_max_length=max(output_list_length)
    return output_max_length+1

input_word_dict,output_word_dict,inputword_list,outputword_list=Input_Output_train(train_dataset)

param_run_args={

    "input_size_encoder":input_word_dict.n_chars,
    "output_size_decoder":output_word_dict.n_chars,
    "hidden_size":  512,
    "num_layers":  1,
    "dropout_encoder":0.4,
    "dropout_decoder": 0.2,
    "batch_size": 128,
    "embedding_size": 512,
    "epochs": 15,
    "cell_type":"GRU",
    "bidirectional": True,
    "attention": True

    }

###############################passed by argpass #############################################################

# param_run_args={
    
# "input_size_encoder":input_word_dict.n_chars,
# "output_size_decoder":output_word_dict.n_chars,
# "hidden_size":  args.hidden_size,
# "num_layers":  args.num_layers,
# "dropout_encoder":args.dropout_encoder,
# "dropout_decoder": args.dropout_decoder,
# "batch_size": args.batch_size,
# "embedding_size": args.embedding_size,
# "epochs": args.epochs,
# "cell_type":args.cell_type,
# "bidirectional": args.bidirectional,
# "attention": args.attention 
    
# }

#################################################################################################################

#use to get the input data in form of list 
def getlistofwords_x(df):
    return df.iloc[:,0].tolist()

#use to get the output data in form of list
def getlistofwords_y(df):
    return df.iloc[:,1].tolist()

valid_input_list = getlistofwords_x(valid_dataset)
max_input_length = max(max(getlength_x(train_dataset),getlength_x(test_dataset)),getlength_x(valid_dataset))



#to form tensor list pass the wordlist,maxlength,dictusing 
# function that takes words as argument and return tensor 
def tensorsFormation(inputword,max_length,input_dict):
    inlist=[]
    for char in inputword:
        inlist.append(input_dict.chartoindex[char])
    inlist.append(EOW_token)
    diff=max_length-len(inlist)
    inlist.extend([PAD_token]*diff)
    wordtensor=torch.tensor(inlist, dtype=torch.long,device=device)
        
    
    return wordtensor

#function to create batch 
def batchcreation(data,batchsize):
    size=len(data)
    batchdata=[]
    # data consist of the list of tensor that is to be converted in batch a list of batch is created and returned 
    for i in range(0,size,batchsize):
        temp=torch.stack(data[i:i+batchsize]).to(device)
        batchdata.append(temp.transpose(0,1))
            
    return batchdata

#this is encoder class which takes as input the english converted tensor and then embedding is done the output tensor is then given to
# hidden layer the output of the hidden layer is given to next Ei hidden layer 
class EncoderRNN(nn.Module):
    def __init__(self, parameters):
        super(EncoderRNN, self).__init__()
        #initializing the parameters
        self.input_size=parameters['input_size_encoder']
        self.dropout = nn.Dropout(parameters['dropout_encoder'])
        self.dropout_val=parameters['dropout_encoder']
        self.num_layers = parameters['num_layers']
        self.batch_size = parameters['batch_size']
        self.embedding_size = parameters['embedding_size']
        self.hidden_size = parameters['hidden_size']
        self.cell_type = parameters['cell_type']
        self.embedding = nn.Embedding(parameters['input_size_encoder'], parameters['embedding_size'])
        self.bidirection = parameters['bidirectional']
        self.attention_val = parameters['attention']
        if(self.bidirection==True):
            self.bidirection_return_val=2
        else:
            self.bidirection_return_val=1
        
        if(self.cell_type == "GRU" ):
            self.cell_calc = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)
        elif(self.cell_type == "LSTM"):
            self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)
        elif(self.cell_type == "RNN"):
            self.cell_calc = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)
   

    def forward(self, input, hidden):
        #the input is passed to the encding that conver the tensor to the embedding size 
        #then the tesnor produced is then drop out is applied to it 
        output = self.dropout(self.embedding(input).view(-1,self.batch_size,self.embedding_size))
        #the result produced is given to cell LSTM , RNN or GRU 
        if(self.cell_type == "LSTM"):
            output,(hidden, cell) = self.lstm(output)
        else:
            output,hidden = self.cell_calc(output, hidden)
                    
        # if bidirection is applied then taking then changing the dimension thaking the average and passing that as output
        if (self.bidirection==True):
            dim1=hidden.size(1)
            dim2=hidden.size(2)
            hidden = hidden.reshape(2, -1, dim1, dim2)
            temp = hidden[0]
            temp.add(hidden[1])
            hidden=0.5*temp
                        
            if(self.cell_type == "LSTM"):
                dim1= cell.size(1)
                dim2= cell.size(2)
                cell = cell.reshape(2,-1,dim1,dim2)
                temp=cell[0]
                temp.add(cell[1])
                cell=0.5*temp
                #if attention is true then chaing the dimension taking average and then adding
            if(self.attention_val==True):
                output=output.permute(2,1,0)
                output = torch.split(output, output.shape[0]//2)
                temp1=torch.permute(output[0],(2,1,0))*0.5
                temp2=torch.permute(output[1],(2,1,0))*0.5
                output = torch.add(temp1,temp2)
        if self.cell_type == "LSTM":
            return output,hidden,cell
        else:
            return output,hidden

    def initHidden(self):
        return torch.zeros(self.bidirection_return_val*self.num_layers, self.batch_size, self.hidden_size).to(device)

class DecoderRNN(nn.Module):
    def __init__(self, parameters):
        super(DecoderRNN, self).__init__()
        self.output_size=parameters['output_size_decoder']
        self.dropout = nn.Dropout(parameters['dropout_decoder'])
        self.dropout_val=parameters['dropout_decoder']
        self.num_layers = parameters['num_layers']
        self.batch_size = parameters['batch_size']
        self.embedding_size = parameters['embedding_size']
        self.hidden_size = parameters['hidden_size']
        self.cell_type = parameters['cell_type']
        self.embedding = nn.Embedding(parameters['output_size_decoder'], parameters['embedding_size'])
        if(self.cell_type == "GRU"):
            self.cell_calc = nn.GRU(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        elif(self.cell_type == "RNN"):
            self.cell_calc = nn.RNN(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        elif(self.cell_type == "LSTM"):
            self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        
        self.output_layer = nn.Linear(self.hidden_size, self.output_size)
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input, hidden):
        #the input given to hidden layer is first embedded then dropout is performed and then passed though the relu activation 
        #layer 
        output = F.relu(self.dropout(self.embedding(input).view(-1, self.batch_size, self.embedding_size)))
        if (self.cell_type=='GRU' or self.cell_type=='RNN'):
            output, hidden = self.cell_calc(output, hidden)
        else:
            output,(hidden,cell) = self.lstm(output,(hidden[0],hidden[1]))
        
        #softmax is done on the output layer to get probability distribution based on cell type we either return output,hidden
        # or output,hidden ,cell tensor if its LSTM 
        if (self.cell_type=='GRU' or self.cell_type=='RNN'):
            return self.softmax(self.output_layer(output[0])),hidden
        else:
            return self.softmax(self.output_layer(output[0])),hidden,cell

class AttnDecoderRNN(nn.Module):
    def __init__(self, parameters):
        super(AttnDecoderRNN, self).__init__()
        self.output_size=parameters['output_size_decoder']
        self.dropout = nn.Dropout(parameters['dropout_decoder'])
        self.dropout_val=parameters['dropout_decoder']
        self.num_layers = parameters['num_layers']
        self.batch_size = parameters['batch_size']
        self.embedding_size = parameters['embedding_size']
        self.hidden_size = parameters['hidden_size']
        self.cell_type = parameters['cell_type']
        self.embedding = nn.Embedding(parameters['output_size_decoder'], parameters['embedding_size'])
        self.attention_layer = nn.Linear(self.hidden_size + self.embedding_size, max_input_length)
        self.attention_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)
        self.dropout = nn.Dropout(self.dropout_val)
        if(self.cell_type == "GRU"):
            self.cell_calc = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        elif(self.cell_type == "LSTM"):
            self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        elif(self.cell_type == "RNN"):
            self.cell_calc = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)
        self.output_layer = nn.Linear(self.hidden_size, self.output_size)
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input, hidden, encoder_outputs):
        input = input.unsqueeze(0)
        #changing the dimension of the encoder output 
        tempencoderop=encoder_outputs.permute(1, 0, 2)
        output = self.dropout(self.embedding(input).view(-1, self.batch_size, self.embedding_size))
        temp1=output[0]
        attn_weights=None
        if self.cell_type == "LSTM":
            temp2=hidden[0][0]
            #concat the output of the output produced embedding and the hidden 
            tempcat=torch.cat((temp1, temp2), 1)
            attn_weights = F.softmax(self.attention_layer(tempcat), dim=1)
        else:
            temp2=hidden[0]
            tempcat=torch.cat((temp1, temp2), 1)
            attn_weights = F.softmax(self.attention_layer(tempcat), dim=1)
            
        attn_applied = torch.bmm(attn_weights.unsqueeze(1),tempencoderop)
        output = torch.cat((output[0], attn_applied.squeeze(1)), 1)
        
        output = F.relu(self.attention_combine(output).unsqueeze(0))
        if(self.cell_type == "GRU" or self.cell_type=="RNN"):
            output, hidden = self.cell_calc(output, hidden)
        else:
            output,(hidden, cell) = self.lstm(output, (hidden[0], hidden[1]))
        
        #the output is returned bsed on the cell type 
        if((self.cell_type == "GRU" or self.cell_type=="RNN")):
            return self.softmax(self.output_layer(output[0])), hidden,attn_weights
        else:
            return self.softmax(self.output_layer(output[0])), hidden,cell,attn_weights

def train(input_batch_tensor, target_batch_tensor,  encoder_optimizer, decoder_optimizer, encoder_obj, decoder_obj,criterion,train_iter_params):
    
    attention=train_iter_params['attention']
    #the gradient are initialized to zero 
    decoder_optimizer.zero_grad()
    encoder_optimizer.zero_grad()
    target_length = target_batch_tensor.size(0)
    
    #the hidden layer is first initialized with all zero 
    encoder_hidden = encoder_obj.initHidden()
    loss = 0
    #based on the cell type the input and hidden tensor is passed to encoder 
    if train_iter_params['cell_type'] == "LSTM":
        encoderop,encoder_hidden, encoder_cell = encoder_obj(input_batch_tensor, encoder_hidden)
    else:
        encoderop,encoder_hidden = encoder_obj(input_batch_tensor, encoder_hidden)
        
    #the input to decoder is start of word depending upon the batch size that many start of words are given to decoder
    decoder_input = torch.tensor([SOW_token]*train_iter_params['batch_size']).to(device)
    decoder_hidden = encoder_hidden
    if train_iter_params['cell_type'] == "LSTM":
        decoder_cell = encoder_cell
    
    #teacher forcing is used 50% of the time 
    teacher_forcing_ratio = 0.5

    if(random.random() < teacher_forcing_ratio):
        use_teacher_forcing = True 
    else:
        use_teacher_forcing=False
        
    if(attention==False):
        if use_teacher_forcing:
            #if we use teacher forcing then we diirectly feed the grounf truth to the decoder 
            for decoderinput_i in range(target_length):
                if train_iter_params['cell_type'] == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))
                else:
                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)
                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])
                decoder_input = target_batch_tensor[decoderinput_i]  
         #if we dont use teacher forcing during traning then feeding the input which was predicted by the previous decoder   
        else:
            
            for decoderinput_i in range(target_length):
                if train_iter_params['cell_type'] == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))
                else:
                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)
                #taking the value and index that is highest in the probability distribution
                topv, topi = decoder_output.topk(1)
                decoder_input = topi.squeeze().detach()  

                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])
    else:
        if use_teacher_forcing:
    #if we use teacher forcing then we diirectly feed the grounf truth to the decoder and as attention is true then we also feed 
    #the encoder output to the decoder based on the attention weights
            for decoderinput_i in range(target_length):
                if train_iter_params['cell_type'] == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell,attention_weights = decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoderop)
                else:
                    decoder_output, decoder_hidden,attention_weights = decoder_obj(decoder_input, decoder_hidden,encoderop)
                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])
                decoder_input = target_batch_tensor[decoderinput_i]  

        else:
    #as teacher forcing is false the previous output of the decode is fed as input to the current decoder along with the atention 
    #weights and encoder output
            
            for decoderinput_i in range(target_length):
                if train_iter_params['cell_type'] == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell ,attention_weights= decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoderop)
                else:
                    decoder_output, decoder_hidden ,attention_weights= decoder_obj(decoder_input, decoder_hidden,encoderop)
                topv, topi = decoder_output.topk(1)
                decoder_input = topi.squeeze().detach()  

                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])

    #this is for backward propogation 
    loss.backward()

    encoder_optimizer.step()
    decoder_optimizer.step()
    
    loss_final= loss.item() *train_iter_params['batch_size']

    return  loss_final/ target_length



def train_setup(encoder, decoder, train_iter_params,parameters):
    
    attention=train_iter_params['attention']
    Total_loss = 0   
    
    #this is the optimizer that is used Nadam 
    encoder_optimizer = optim.NAdam(encoder.parameters(), lr=train_iter_params['learning_rate'], weight_decay = 0.0003)
    decoder_optimizer = optim.NAdam(decoder.parameters(), lr=train_iter_params['learning_rate'], weight_decay = 0.0003)
    # loss used is crossentropy 
    criterion = nn.CrossEntropyLoss()
    
    #this is used to create a tensor from words for the train input ie for english words 
    input_tensor_list=[]

    for i in range(len(inputword_list)):
        if(attention == False and i%train_iter_params['batch_size']==0 ):
            max_length_x=getlength_x(train_dataset[i:i+train_iter_params['batch_size']])
        elif(attention == True):
            max_length_x=max_input_length

        inputwordtensor =tensorsFormation(inputword_list[i],max_length_x,input_word_dict)
        input_tensor_list.append(inputwordtensor)
    
    #this is used to create a tensor of the hindi output corresponding to the train dataset
    
    output_tensor_list=[]

    for i in range(len(outputword_list)):
        if(i%train_iter_params['batch_size']==0):
            max_length_y=getlength_y(train_dataset[i:i+train_iter_params['batch_size']])
                  
        outputwordtesor = tensorsFormation(outputword_list[i],max_length_y,output_word_dict)
        output_tensor_list.append(outputwordtesor)
    
    #this is used to create tesnor of list for the valid input dataset 

    valid_iptensor_list=[]

    for i in range(len(valid_input_list)):
        if(attention == False and i%train_iter_params['batch_size']==0):
            valid_max_length_x=getlength_x(valid_dataset[i:i+train_iter_params['batch_size']])
        elif(attention == True):
            valid_max_length_x=max_input_length
        validipwordtensor =tensorsFormation(valid_input_list[i],valid_max_length_x,input_word_dict)
        valid_iptensor_list.append(validipwordtensor)

    #creating batch for train input,output, and valid input dataset 
    train_batch_input = batchcreation(input_tensor_list, train_iter_params['batch_size'])
    train_batch_output = batchcreation(output_tensor_list, train_iter_params['batch_size'])
    valid_batch_input = batchcreation(valid_iptensor_list, train_iter_params['batch_size'])
   
    no_of_batches=len(train_batch_output)
    no_of_datapoints=train_iter_params['batch_size']*no_of_batches
    
               
    for count in range(train_iter_params['epochs']):
        print('epoch count is ',count+1)
        #data is sent batch wise to train function which return the loss 
        for i in range(no_of_batches):
            loss = train(train_batch_input[i], train_batch_output[i], encoder_optimizer, decoder_optimizer,encoder,decoder,criterion,train_iter_params)
            Total_loss += loss
                
        
        avg_loss = Total_loss/no_of_datapoints
        #reset the total_loss for next epoch
        Total_loss = 0
        print("average loss at ", count+1, " epochs is ", avg_loss)
        valid_output_list = getlistofwords_y(valid_dataset)
        #calling cal_accuracy to calculate the accuracy on valid dataset based on cuurent trainind model
        valid_accuracy = cal_Accuracy(valid_batch_input, valid_output_list, train_iter_params['cell_type'], train_iter_params['batch_size'],encoder,decoder,train_iter_params['attention'])
        
        print("Valid accuracy is ", valid_accuracy)
        #when running sweeep 
        #wandb.log({"validation_accuracy": valid_accuracy, "training_loss": avg_loss})

def evaluate(encoder_obj, decoder_obj, input_tensors, cell_type,batch_size,attention):
    with torch.no_grad():
        #as we dont want to calculate the gradient while evaluating so we will do a fwd pass 
        predicted_word_tensor=[]
        encoder_hidden = encoder_obj.initHidden()
        # based on the cell type we get the values from encoder 
        if (cell_type=='GRU' or cell_type=='RNN'):
            encoder_output,encoder_hidden = encoder_obj(input_tensors, encoder_hidden)
        else:
            encoder_output,encoder_hidden, encoder_cell = encoder_obj(input_tensors, encoder_hidden)

        #the first input to decoder will be SOW 
        decoder_input = torch.tensor([SOW_token]*batch_size).to(device)  # SOW

        decoder_hidden = encoder_hidden
        if cell_type == "LSTM":
            decoder_cell = encoder_cell
               
        #we will run the decoder till the largest input present in the batch     
        for i in range(input_tensors.size(0)):
            
            if(attention==False):
                if cell_type == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))
                else:
                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)
                topv, topi = decoder_output.data.topk(1)
            else:
                if cell_type == "LSTM":
                    decoder_output, decoder_hidden, decoder_cell,attn_weights = decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoder_output)
                else:
                    decoder_output, decoder_hidden,attn_weights = decoder_obj(decoder_input, decoder_hidden,encoder_output)
                topv, topi = decoder_output.data.topk(1)
                
                
            #predicted word is used to store the tensor that is formed for the input word                        
            temp=topi.view(1,-1).squeeze()
            predicted_word_tensor.append(temp)
            decoder_input = topi.squeeze().detach()
            
        predicted_word_tensor=torch.stack(predicted_word_tensor,dim=1).to(device)
        
        return predicted_word_tensor



def cal_Accuracy(input, actual_output, cell_type, batch_size,encoder1,decoder1,attention):
    correct_output=0
    no_of_batch=len(input)
    no_of_datapoints=batch_size*no_of_batch 
        
    for i in range(no_of_batch):
        output_tensor_predicted = evaluate(encoder1, decoder1, input[i], cell_type,batch_size,attention)
        #this evalute will return the predicted tensor
        #once we get the input tenor we parse and convert it to hindi word till we reach EOW or padded token then that 
        #word is compared to the actual output 
        for j in range(output_tensor_predicted.size(0)):
            string=""
            for k in range(output_tensor_predicted.size(1)):
                target_val=output_tensor_predicted[j][k].item()
                if(target_val==EOW_token or target_val==PAD_token):
                    break
                else:
                    string =string+output_word_dict.indextochar[target_val]
            
            if(actual_output[i*batch_size+j]==string):
                correct_output+=1
    
    return (correct_output/no_of_datapoints *100)

#this is fuction similar to cal_accuracy but it also return the translated output aling with accuracy 
def cal_Accuracy_test(input, actual_output, cell_type, batch_size,encoder1,decoder1,attention):
    correct_output=0
    no_of_batch=len(input)
    no_of_datapoints=batch_size*no_of_batch 
    list_word_predicted=[]
    
    for i in range(no_of_batch):
        output_tensor_predicted = evaluate(encoder1, decoder1, input[i], cell_type,batch_size,attention)
        # ruuning a for loop to conver the tensor to hindi word                 
        for j in range(output_tensor_predicted.size(0)):
            string=""
            for k in range(output_tensor_predicted.size(1)):
                target_val=output_tensor_predicted[j][k].item()
                if(target_val==EOW_token or target_val==PAD_token):
                    break
                else:
                    string =string+output_word_dict.indextochar[target_val]
            
            list_word_predicted.append(string)
            #if hindi actual output equal to translated output then increase the count by +1
            if(actual_output[i*batch_size+j]==string):
                correct_output+=1
    
    return (list_word_predicted,correct_output/no_of_datapoints *100)

# this function takes the configurations and the trained model encoder decoder as input and calculate the testaccuracy 
# and return the translated list 
def getprediceted_list_test(paramet,encodertest,decodertest):
    # first below we conver the test english word to tensor then create the batch depending upon the size 
    test_inputword_list=getlistofwords_x(test_dataset)
    testinput_tensor_list=[]
    attention=paramet['attention']
    # tensor are formed based on attention or vanilla model 
    for i in range(len(test_inputword_list)):
        if(attention == False and i%paramet['batch_size']==0 ):
            max_length_x=getlength_x(test_dataset[i:i+paramet['batch_size']])
        elif(attention == True):
            max_length_x=max_input_length

        testinputwordtensor =tensorsFormation(test_inputword_list[i],max_length_x,input_word_dict)
        testinput_tensor_list.append(testinputwordtensor)
    #forming batch for test dataset input 
    test_batch_input = batchcreation(testinput_tensor_list, paramet['batch_size'])
    test_output_list= getlistofwords_y(test_dataset)
    list_word_predicted,test_accuracy = cal_Accuracy_test(test_batch_input, test_output_list, paramet['cell_type'], paramet['batch_size'],encodertest,decodertest,paramet['attention'])
    print('test_accuracy is ',test_accuracy)
    return list_word_predicted



def main_fn(param_run_args):
    #first training the model with attention and calculating the test accuracy on that 
    attention = True
    paramet= {

    "input_size_encoder":input_word_dict.n_chars,
    "output_size_decoder":output_word_dict.n_chars,
    "hidden_size":  512,
    "num_layers":  1,
    "dropout_encoder":0.2,
    "dropout_decoder": 0.4,
    "batch_size": 256,
    "embedding_size": 512,
    "epochs": 15,
    "cell_type":"LSTM",
    "bidirectional": True,
    "attention": True
    }     

    encodertest = EncoderRNN(paramet).to(device)
    if(attention==False):
        decodertest = DecoderRNN(paramet).to(device)
    else:
        decodertest=AttnDecoderRNN(paramet).to(device)


    train_iter_params={
        'epochs':paramet['epochs'],
        'learning_rate':0.001,
        'batch_size':paramet['batch_size'],
        'cell_type':paramet['cell_type'] ,
         "attention": attention


     }
    train_setup(encodertest, decodertest, train_iter_params,paramet)
    list_word_predicted_atten=getprediceted_list_test(paramet,encodertest,decodertest)
    #capturing the translated output

    test_output_df = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',names=['input','output'])

    #when using on local machine comment the above line and uncomment the below line
    #test_output_df = pd.read_csv(test_dataset_path,names=['input','output'])


    test_output_df['predicted_output']=list_word_predicted_atten
    test_output_df.to_csv('resultattention.csv')
    
    #training the model without attention and calculating the test accuracy 
    attention = False

    paramet= {

    "input_size_encoder":input_word_dict.n_chars,
    "output_size_decoder":output_word_dict.n_chars,
    "hidden_size":  512,
    "num_layers":  2,
    "dropout_encoder":0.4,
    "dropout_decoder": 0.3,
    "batch_size": 64,
    "embedding_size": 512,
    "epochs": 10,
    "cell_type":"LSTM",
    "attention": attention,
    "bidirectional": True,
        

    }

    encodertest = EncoderRNN(paramet).to(device)
    if(attention==False):
        decodertest = DecoderRNN(paramet).to(device)
    else:
        decodertest=AttnDecoderRNN(paramet).to(device)


    train_iter_params={
        'epochs':paramet['epochs'],
        'learning_rate':0.001,
        'batch_size':paramet['batch_size'],
        'cell_type':paramet['cell_type'],
        "attention": attention


     }
    
    
    train_setup(encodertest, decodertest, train_iter_params,paramet)
    list_word_predicted_vanilla=getprediceted_list_test(paramet,encodertest,decodertest)
    #capturing the output without attention 

    test_output_df = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',names=['input','output'])
    #when using on local machine comment the above line and uncomment the below line
    #test_output_df = pd.read_csv(test_dataset_path,names=['input','output'])


    test_output_df['predicted_output']=list_word_predicted_vanilla
    test_output_df.to_csv('resultvanilla.csv')

    #this is to output where the attention model give a correct prediction and vanilla model dont 
    test_actual_output=getlistofwords_y(test_dataset)
    test_actual_input =getlistofwords_x(test_dataset)
    count_corrected_pre=0
    for i in range(len(test_actual_output)):
        if(test_actual_output[i]==list_word_predicted_atten[i] and test_actual_output[i]!=list_word_predicted_vanilla[i]):
            print('input is ',test_actual_input[i])
            print('actual output is ',test_actual_output[i])
            print('output using attention ',list_word_predicted_atten[i])
            print('output without attention ',list_word_predicted_vanilla[i])
            print('-------------------------------------------------------------------')
            count_corrected_pre+=1
            if(count_corrected_pre==5):
                break
                
    print('below model is trained using the parameter passed using argpass if no parameter pass defualt values are taken ')
    
    attention =param_run_args['attention']
    
    encodertest = EncoderRNN(param_run_args).to(device)
    if(attention==False):
        decodertest = DecoderRNN(param_run_args).to(device)
    else:
        decodertest=AttnDecoderRNN(param_run_args).to(device)


    train_iter_params={
        'epochs':param_run_args['epochs'],
        'learning_rate':0.001,
        'batch_size':param_run_args['batch_size'],
        'cell_type':param_run_args['cell_type'] ,
         "attention": attention


     }
    train_setup(encodertest, decodertest, train_iter_params,param_run_args)
    list_word_predicted_atten=getprediceted_list_test(param_run_args,encodertest,decodertest)

main_fn(param_run_args)

#this is to run sweep 
# def runsweep():
#     config = None
#     with wandb.init(config = config, entity = 'singhbhavesh999') as run:
#         config = wandb.config
#         run.name='hl_'+str(config.hidden_layer)+'_bs_'+str(config.batch_size)+'_ct_'+config.cell_type
#         #run.name = "EBS_{}_NL_{}_HL_{}_CellT_{}_BS_{}".format(config.embedding_size, config.num_layers, config.hidden_layer, config.cell_type,config.batch_size)
#         param = {

#             "input_size_encoder":input_word_dict.n_chars,
#             "output_size_decoder":output_word_dict.n_chars,
#             "hidden_size":  wandb.config.hidden_layer,
#             "num_layers":  wandb.config.num_layers,
#             "dropout_encoder":wandb.config.dropout_encoder,
#             "dropout_decoder": wandb.config.dropout_decoder,
#             "batch_size": wandb.config.batch_size,
#             "embedding_size": wandb.config.embedding_size,
#             "epochs": wandb.config.epochs,
#             "cell_type":wandb.config.cell_type,
#             "bidirectional": wandb.config.bidirectional

#         }
        
        
        

       
#         encoder1 = EncoderRNN(param).to(device)
#         if(attention==False):
#             decoder1 = DecoderRNN(param).to(device)
#         else:
#             decoder1=AttnDecoderRNN(param).to(device)


#         train_iter_params={
#             'epochs':param['epochs'],
#             'learning_rate':0.001,
#             'batch_size':param['batch_size'],
#             'cell_type':param['cell_type']  
#             }

#         train_setup(encoder1, decoder1, train_iter_params,param)

 

# wandb.agent(sweep_id, runsweep, count = 2)

