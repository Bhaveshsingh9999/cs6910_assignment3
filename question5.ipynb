{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport wandb\nimport random\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-19T07:50:20.137524Z","iopub.execute_input":"2023-05-19T07:50:20.138236Z","iopub.status.idle":"2023-05-19T07:50:20.144005Z","shell.execute_reply.started":"2023-05-19T07:50:20.138200Z","shell.execute_reply":"2023-05-19T07:50:20.143062Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='44fa96b263794ea519fb29399eb6b8f469eb934b')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:22.050260Z","iopub.execute_input":"2023-05-19T07:50:22.051306Z","iopub.status.idle":"2023-05-19T07:50:22.157295Z","shell.execute_reply.started":"2023-05-19T07:50:22.051254Z","shell.execute_reply":"2023-05-19T07:50:22.156361Z"},"trusted":true},"execution_count":183,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinghbhavesh999\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"#wandb.login(key='b0bbea67b5b95cece4e781392ed3f568328da17e')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:22.818964Z","iopub.execute_input":"2023-05-19T07:50:22.819316Z","iopub.status.idle":"2023-05-19T07:50:22.823554Z","shell.execute_reply.started":"2023-05-19T07:50:22.819285Z","shell.execute_reply":"2023-05-19T07:50:22.822487Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"##44fa96b263794ea519fb29399eb6b8f469eb934b","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:23.470391Z","iopub.execute_input":"2023-05-19T07:50:23.471389Z","iopub.status.idle":"2023-05-19T07:50:23.476510Z","shell.execute_reply.started":"2023-05-19T07:50:23.471340Z","shell.execute_reply":"2023-05-19T07:50:23.475534Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv',header=None)\ntest_dataset=pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',header=None)\nvalid_dataset=pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv' ,header=None)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:24.171368Z","iopub.execute_input":"2023-05-19T07:50:24.172054Z","iopub.status.idle":"2023-05-19T07:50:24.264268Z","shell.execute_reply.started":"2023-05-19T07:50:24.172017Z","shell.execute_reply":"2023-05-19T07:50:24.263238Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lang2_ = 'HINDI'\nSOW_token = 0 #<\nEOW_token = 1 #>\nUNK_token = 2 #_\nPAD_token = 3 #@\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:25.571721Z","iopub.execute_input":"2023-05-19T07:50:25.572158Z","iopub.status.idle":"2023-05-19T07:50:25.577391Z","shell.execute_reply.started":"2023-05-19T07:50:25.572116Z","shell.execute_reply":"2023-05-19T07:50:25.576381Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n  \n  \"metric\": {\n      \"name\":\"validation_accuracy\",\n      \"goal\": \"maximize\"\n  },\n  \"method\": \"bayes\",\n  \"parameters\": {\n        \"bidirectional\": {\n            \"values\": [True,False]\n        },\n        \"embedding_size\": {\n            \"values\": [512, 256, 64, 32]\n        },\n        \"hidden_layer\": {\n            \"values\": [512, 256, 128]\n        },\n        \"epochs\": {\n            \"values\": [10,15]\n        },\n        \"cell_type\": {\n            \"values\": [\"RNN\",\"GRU\",\"LSTM\"]\n        },\n        \"num_layers\": {\n            \"values\": [3, 2, 1]\n        },\n        \"dropout_encoder\": {\n            \"values\": [0.2, 0.3, 0.4]\n        },\n        \"dropout_decoder\": {\n            \"values\": [0.2, 0.3, 0.4]\n        },\n        \"batch_size\": {\n            \"values\": [256, 128, 64]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config, project=\"DLSeqtoseq\")","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:26.415955Z","iopub.execute_input":"2023-05-19T07:50:26.417027Z","iopub.status.idle":"2023-05-19T07:50:26.738229Z","shell.execute_reply.started":"2023-05-19T07:50:26.416978Z","shell.execute_reply":"2023-05-19T07:50:26.737198Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stdout","text":"Create sweep with ID: e09q2jvw\nSweep URL: https://wandb.ai/singhbhavesh999/DLSeqtoseq/sweeps/e09q2jvw\n","output_type":"stream"}]},{"cell_type":"code","source":"class make_dict:\n    def __init__(self,name):\n        self.name=name\n        self.chartoindex={}\n        self.indextochar={SOW_token: \"<\", EOW_token: \">\",UNK_token:\"_\",PAD_token:'@'}\n        self.n_chars=4\n    \n    def addchar(self,word):\n        for char in word:\n            if char not in self.chartoindex:\n                self.chartoindex[char]=self.n_chars\n                self.indextochar[self.n_chars]=char\n                self.n_chars+=1\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:26.740104Z","iopub.execute_input":"2023-05-19T07:50:26.740459Z","iopub.status.idle":"2023-05-19T07:50:26.748414Z","shell.execute_reply.started":"2023-05-19T07:50:26.740405Z","shell.execute_reply":"2023-05-19T07:50:26.746999Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"# doing it on train a dataframe is given as input having input output \n# and it make the disctionary based on that and return input_dict_obj,outout_dict_obj\n\ndef Input_Output_train(df):\n    #convert the dataframe to list \n    input_word=df.iloc[:,0].tolist()\n    output_word=df.iloc[:,1].tolist()\n    input_lang=make_dict('ENG')\n    output_lang=make_dict('HINDI')\n    \n    # to make a dictionary of characters for the input language \n    for word in input_word:\n        input_lang.addchar(word)\n   # to make a dictionary of characters for teh output language \n    for word in output_word:\n        output_lang.addchar(word)\n    return input_lang,output_lang,input_word,output_word\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:27.331284Z","iopub.execute_input":"2023-05-19T07:50:27.332737Z","iopub.status.idle":"2023-05-19T07:50:27.339537Z","shell.execute_reply.started":"2023-05-19T07:50:27.332688Z","shell.execute_reply":"2023-05-19T07:50:27.338483Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use to get max length+1 among the input words dataframe provided as input to the function \ndef getlength_x(df):\n    input_list = df.iloc[:,0].tolist()\n    input_list_length=[]\n    for word in input_list:\n        input_list_length.append(len(word))\n    \n    input_max_length=max(input_list_length)\n    return input_max_length+1\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:28.410470Z","iopub.execute_input":"2023-05-19T07:50:28.411471Z","iopub.status.idle":"2023-05-19T07:50:28.417238Z","shell.execute_reply.started":"2023-05-19T07:50:28.411381Z","shell.execute_reply":"2023-05-19T07:50:28.416217Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"#use to get max length+1 among the output words dataframe provided as input to the function \ndef getlength_y(df):\n    output_list =df.iloc[:,1].tolist()\n    output_list_length=[]\n    for word in output_list:\n        output_list_length.append(len(word))\n    output_max_length=max(output_list_length)\n    return output_max_length+1\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:28.999838Z","iopub.execute_input":"2023-05-19T07:50:29.001825Z","iopub.status.idle":"2023-05-19T07:50:29.007412Z","shell.execute_reply.started":"2023-05-19T07:50:29.001784Z","shell.execute_reply":"2023-05-19T07:50:29.006336Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"input_word_dict,output_word_dict,inputword_list,outputword_list=Input_Output_train(train_dataset)\nattention=True","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:29.559301Z","iopub.execute_input":"2023-05-19T07:50:29.560279Z","iopub.status.idle":"2023-05-19T07:50:29.669836Z","shell.execute_reply.started":"2023-05-19T07:50:29.560241Z","shell.execute_reply":"2023-05-19T07:50:29.668805Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"attention","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:32.249857Z","iopub.execute_input":"2023-05-19T07:50:32.250215Z","iopub.status.idle":"2023-05-19T07:50:32.256442Z","shell.execute_reply.started":"2023-05-19T07:50:32.250185Z","shell.execute_reply":"2023-05-19T07:50:32.255499Z"},"trusted":true},"execution_count":194,"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"#use to get the data in form of list \ndef getlistofwords_x(df):\n    return df.iloc[:,0].tolist()\n\ndef getlistofwords_y(df):\n    return df.iloc[:,1].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:32.795902Z","iopub.execute_input":"2023-05-19T07:50:32.796638Z","iopub.status.idle":"2023-05-19T07:50:32.802547Z","shell.execute_reply.started":"2023-05-19T07:50:32.796599Z","shell.execute_reply":"2023-05-19T07:50:32.801090Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"valid_input_list = getlistofwords_x(valid_dataset)\nmax_input_length = max(max(getlength_x(train_dataset),getlength_x(test_dataset)),getlength_x(valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:33.292156Z","iopub.execute_input":"2023-05-19T07:50:33.292570Z","iopub.status.idle":"2023-05-19T07:50:33.312031Z","shell.execute_reply.started":"2023-05-19T07:50:33.292537Z","shell.execute_reply":"2023-05-19T07:50:33.310589Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to form tensor list pass the wordlist,maxlength,dictusing \n# function that takes words as argument and return tensor \ndef tensorsFormation(inputword,max_length,input_dict):\n    inlist=[]\n    for char in inputword:\n        inlist.append(input_dict.chartoindex[char])\n    inlist.append(EOW_token)\n    diff=max_length-len(inlist)\n    inlist.extend([PAD_token]*diff)\n    wordtensor=torch.tensor(inlist, dtype=torch.long,device=device)\n        \n    \n    return wordtensor","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:34.459090Z","iopub.execute_input":"2023-05-19T07:50:34.459462Z","iopub.status.idle":"2023-05-19T07:50:34.465691Z","shell.execute_reply.started":"2023-05-19T07:50:34.459411Z","shell.execute_reply":"2023-05-19T07:50:34.464657Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"#function to create batch \ndef batchcreation(data,batchsize):\n    size=len(data)\n    batchdata=[]\n    for i in range(0,size,batchsize):\n        temp=torch.stack(data[i:i+batchsize]).to(device)\n        batchdata.append(temp.transpose(0,1))\n            \n    return batchdata","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:35.069344Z","iopub.execute_input":"2023-05-19T07:50:35.069764Z","iopub.status.idle":"2023-05-19T07:50:35.076028Z","shell.execute_reply.started":"2023-05-19T07:50:35.069729Z","shell.execute_reply":"2023-05-19T07:50:35.074963Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, parameters):\n        super(EncoderRNN, self).__init__()\n        self.input_size=parameters['input_size_encoder']\n        self.dropout = nn.Dropout(parameters['dropout_encoder'])\n        self.dropout_val=parameters['dropout_encoder']\n        self.num_layers = parameters['num_layers']\n        self.batch_size = parameters['batch_size']\n        self.embedding_size = parameters['embedding_size']\n        self.hidden_size = parameters['hidden_size']\n        self.cell_type = parameters['cell_type']\n        self.embedding = nn.Embedding(parameters['input_size_encoder'], parameters['embedding_size'])\n        self.bidirection = parameters['bidirectional']\n        if(self.bidirection==True):\n            self.bidirection_return_val=2\n        else:\n            self.bidirection_return_val=1\n        \n        if(self.cell_type == \"GRU\" ):\n            self.cell_calc = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)\n        elif(self.cell_type == \"LSTM\"):\n            self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)\n        elif(self.cell_type == \"RNN\"):\n            self.cell_calc = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.dropout_val, bidirectional = self.bidirection)\n\n    def forward(self, input, hidden):\n        output = self.dropout(self.embedding(input).view(-1,self.batch_size,self.embedding_size))\n#         output = self.dropout(embedded)\n        if(self.cell_type == \"LSTM\"):\n            output,(hidden, cell) = self.lstm(output)\n        else:\n            output,hidden = self.cell_calc(output, hidden)\n                    \n        if (self.bidirection==True):\n            #rehsaping the hidden layer to calculate the avg of the two layers \n            \n            dim1=hidden.size(1)\n            dim2=hidden.size(2)\n            hidden = hidden.reshape(2, -1, dim1, dim2)\n            #print(hidden.shape)\n            temp = hidden[0]\n            temp.add(hidden[1])\n            hidden=0.5*temp\n            \n            \n            if(self.cell_type == \"LSTM\"):\n                dim1= cell.size(1)\n                dim2= cell.size(2)\n                cell = cell.reshape(2,-1,dim1,dim2)\n                temp=cell[0]\n                temp.add(cell[1])\n                cell=0.5*temp\n            if(attention==True):\n                output=output.permute(2,1,0)\n                output = torch.split(output, output.shape[0]//2)\n                temp1=torch.permute(output[0],(2,1,0))*0.5\n                temp2=torch.permute(output[1],(2,1,0))*0.5\n                output = torch.add(temp1,temp2)\n        if self.cell_type == \"LSTM\":\n            return output,hidden,cell\n        else:\n            return output,hidden\n\n    def initHidden(self):\n        return torch.zeros(self.bidirection_return_val*self.num_layers, self.batch_size, self.hidden_size).to(device)\n#         if self.bidirection:\n#             return torch.zeros(2*self.num_layers, self.batch_size, self.hidden_size).to(device)\n#         else:\n#             return torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:35.609810Z","iopub.execute_input":"2023-05-19T07:50:35.610171Z","iopub.status.idle":"2023-05-19T07:50:35.640382Z","shell.execute_reply.started":"2023-05-19T07:50:35.610138Z","shell.execute_reply":"2023-05-19T07:50:35.639259Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, parameters):\n        super(DecoderRNN, self).__init__()\n        self.output_size=parameters['output_size_decoder']\n        self.dropout = nn.Dropout(parameters['dropout_decoder'])\n        self.dropout_val=parameters['dropout_decoder']\n        self.num_layers = parameters['num_layers']\n        self.batch_size = parameters['batch_size']\n        self.embedding_size = parameters['embedding_size']\n        self.hidden_size = parameters['hidden_size']\n        self.cell_type = parameters['cell_type']\n        self.embedding = nn.Embedding(parameters['output_size_decoder'], parameters['embedding_size'])\n               \n       \n        if(self.cell_type == \"GRU\"):\n            self.cell_calc = nn.GRU(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        elif(self.cell_type == \"RNN\"):\n            self.cell_calc = nn.RNN(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        elif(self.cell_type == \"LSTM\"):\n            self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        \n        self.output_layer = nn.Linear(self.hidden_size, self.output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = F.relu(self.dropout(self.embedding(input).view(-1, self.batch_size, self.embedding_size)))\n        if (self.cell_type=='GRU' or self.cell_type=='RNN'):\n            output, hidden = self.cell_calc(output, hidden)\n        else:\n            output,(hidden,cell) = self.lstm(output,(hidden[0],hidden[1]))\n        \n        if (self.cell_type=='GRU' or self.cell_type=='RNN'):\n            return self.softmax(self.output_layer(output[0])),hidden\n        else:\n            return self.softmax(self.output_layer(output[0])),hidden,cell\n            \n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:36.139809Z","iopub.execute_input":"2023-05-19T07:50:36.140149Z","iopub.status.idle":"2023-05-19T07:50:36.154746Z","shell.execute_reply.started":"2023-05-19T07:50:36.140122Z","shell.execute_reply":"2023-05-19T07:50:36.153639Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"class AttnDecoderRNN(nn.Module):\n    def __init__(self, parameters):\n        super(AttnDecoderRNN, self).__init__()\n        self.output_size=parameters['output_size_decoder']\n        self.dropout = nn.Dropout(parameters['dropout_decoder'])\n        self.dropout_val=parameters['dropout_decoder']\n        self.num_layers = parameters['num_layers']\n        self.batch_size = parameters['batch_size']\n        self.embedding_size = parameters['embedding_size']\n        self.hidden_size = parameters['hidden_size']\n        self.cell_type = parameters['cell_type']\n        self.embedding = nn.Embedding(parameters['output_size_decoder'], parameters['embedding_size'])\n        self.attention_layer = nn.Linear(self.hidden_size + self.embedding_size, max_input_length)\n        self.attention_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_val)\n        if(self.cell_type == \"GRU\"):\n            self.cell_calc = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        elif(self.cell_type == \"LSTM\"):\n            self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        elif(self.cell_type == \"RNN\"):\n            self.cell_calc = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.num_layers, dropout = self.dropout_val)\n        self.output_layer = nn.Linear(self.hidden_size, self.output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden, encoder_outputs):\n        input = input.unsqueeze(0)\n        tempencoderop=encoder_outputs.permute(1, 0, 2)\n        output = self.dropout(self.embedding(input).view(-1, self.batch_size, self.embedding_size))\n        temp1=output[0]\n        attn_weights=None\n        if self.cell_type == \"LSTM\":\n            temp2=hidden[0][0]\n            tempcat=torch.cat((temp1, temp2), 1)\n            attn_weights = F.softmax(self.attention_layer(tempcat), dim=1)\n        else:\n            temp2=hidden[0]\n            tempcat=torch.cat((temp1, temp2), 1)\n            attn_weights = F.softmax(self.attention_layer(tempcat), dim=1)\n            \n        attn_applied = torch.bmm(attn_weights.unsqueeze(1),tempencoderop)\n        output = torch.cat((output[0], attn_applied.squeeze(1)), 1)\n        output = F.relu(self.attention_combine(output).unsqueeze(0))\n        if(self.cell_type == \"GRU\" or self.cell_type==\"RNN\"):\n            output, hidden = self.cell_calc(output, hidden)\n        else:\n            output,(hidden, cell) = self.lstm(output, (hidden[0], hidden[1]))\n        \n        if((self.cell_type == \"GRU\" or self.cell_type==\"RNN\")):\n            return self.softmax(self.output_layer(output[0])), hidden,attn_weights\n        else:\n            return self.softmax(self.output_layer(output[0])), hidden,cell,attn_weights\n        \n        \n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:36.717664Z","iopub.execute_input":"2023-05-19T07:50:36.718045Z","iopub.status.idle":"2023-05-19T07:50:36.736590Z","shell.execute_reply.started":"2023-05-19T07:50:36.718011Z","shell.execute_reply":"2023-05-19T07:50:36.735463Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"def train(input_batch_tensor, target_batch_tensor,  encoder_optimizer, decoder_optimizer, encoder_obj, decoder_obj,criterion,train_iter_params):\n    \n\n    decoder_optimizer.zero_grad()\n    encoder_optimizer.zero_grad()\n    target_length = target_batch_tensor.size(0)\n    encoder_hidden = encoder_obj.initHidden()\n    loss = 0\n    if train_iter_params['cell_type'] == \"LSTM\":\n        encoderop,encoder_hidden, encoder_cell = encoder_obj(input_batch_tensor, encoder_hidden)\n    else:\n        encoderop,encoder_hidden = encoder_obj(input_batch_tensor, encoder_hidden)\n        \n    decoder_input = torch.tensor([SOW_token]*train_iter_params['batch_size']).to(device)\n    decoder_hidden = encoder_hidden\n    if train_iter_params['cell_type'] == \"LSTM\":\n        decoder_cell = encoder_cell\n    \n    teacher_forcing_ratio = 0.5\n\n    if(random.random() < teacher_forcing_ratio):\n        use_teacher_forcing = True \n    else:\n        use_teacher_forcing=False\n        \n    if(attention==False):\n        if use_teacher_forcing:\n            \n            for decoderinput_i in range(target_length):\n                if train_iter_params['cell_type'] == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))\n                else:\n                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)\n                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])\n                decoder_input = target_batch_tensor[decoderinput_i]  \n\n        else:\n            \n            for decoderinput_i in range(target_length):\n                if train_iter_params['cell_type'] == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))\n                else:\n                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)\n                topv, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze().detach()  \n\n                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])\n    else:\n        if use_teacher_forcing:\n            \n            for decoderinput_i in range(target_length):\n                if train_iter_params['cell_type'] == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell,attention_weights = decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoderop)\n                else:\n                    decoder_output, decoder_hidden,attention_weights = decoder_obj(decoder_input, decoder_hidden,encoderop)\n                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])\n                decoder_input = target_batch_tensor[decoderinput_i]  \n\n        else:\n            \n            for decoderinput_i in range(target_length):\n                if train_iter_params['cell_type'] == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell ,attention_weights= decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoderop)\n                else:\n                    decoder_output, decoder_hidden ,attention_weights= decoder_obj(decoder_input, decoder_hidden,encoderop)\n                topv, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze().detach()  \n\n                loss += criterion(decoder_output, target_batch_tensor[decoderinput_i])\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    \n    loss_final= loss.item() *train_iter_params['batch_size']\n\n    return  loss_final/ target_length","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:37.246171Z","iopub.execute_input":"2023-05-19T07:50:37.246935Z","iopub.status.idle":"2023-05-19T07:50:37.263943Z","shell.execute_reply.started":"2023-05-19T07:50:37.246887Z","shell.execute_reply":"2023-05-19T07:50:37.262943Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_setup(encoder, decoder, train_iter_params,parameters):\n    \n    \n    Total_loss = 0  # Reset every print_every\n    \n    \n    encoder_optimizer = optim.NAdam(encoder.parameters(), lr=train_iter_params['learning_rate'], weight_decay = 0.0005)\n    decoder_optimizer = optim.NAdam(decoder.parameters(), lr=train_iter_params['learning_rate'], weight_decay = 0.0005)\n    \n    criterion = nn.CrossEntropyLoss()\n    \n    \n    \n    input_tensor_list=[]\n\n    for i in range(len(inputword_list)):\n        if(attention == False and i%train_iter_params['batch_size']==0 ):\n            max_length_x=getlength_x(train_dataset[i:i+train_iter_params['batch_size']])\n        elif(attention == True):\n            max_length_x=max_input_length\n\n        inputwordtensor =tensorsFormation(inputword_list[i],max_length_x,input_word_dict)\n        input_tensor_list.append(inputwordtensor)\n    \n    output_tensor_list=[]\n\n    for i in range(len(outputword_list)):\n        if(i%train_iter_params['batch_size']==0):\n            max_length_y=getlength_y(train_dataset[i:i+train_iter_params['batch_size']])\n                  \n        outputwordtesor = tensorsFormation(outputword_list[i],max_length_y,output_word_dict)\n        output_tensor_list.append(outputwordtesor)\n\n    valid_iptensor_list=[]\n\n    for i in range(len(valid_input_list)):\n        if(attention == False and i%train_iter_params['batch_size']==0):\n            valid_max_length_x=getlength_x(valid_dataset[i:i+train_iter_params['batch_size']])\n        elif(attention == True):\n            valid_max_length_x=max_input_length\n        validipwordtensor =tensorsFormation(valid_input_list[i],valid_max_length_x,input_word_dict)\n        valid_iptensor_list.append(validipwordtensor)\n\n    \n    train_batch_input = batchcreation(input_tensor_list, train_iter_params['batch_size'])\n    train_batch_output = batchcreation(output_tensor_list, train_iter_params['batch_size'])\n    valid_batch_input = batchcreation(valid_iptensor_list, train_iter_params['batch_size'])\n\n\n    \n    \n    no_of_batches=len(train_batch_output)\n    no_of_datapoints=train_iter_params['batch_size']*no_of_batches\n   \n        \n    for count in range(train_iter_params['epochs']):\n        print('epoch count is ',count+1)\n        for i in range(no_of_batches):\n            loss = train(train_batch_input[i], train_batch_output[i], encoder_optimizer, decoder_optimizer,encoder,\n                         decoder,criterion,train_iter_params)\n            Total_loss += loss\n                \n\n        avg_loss = Total_loss/no_of_datapoints\n        Total_loss = 0\n        print(\"average loss at  \", count+1, \"epochs is \", avg_loss)\n        valid_output_list = getlistofwords_y(valid_dataset)\n        valid_accuracy = cal_Accuracy(valid_batch_input, valid_output_list, train_iter_params['cell_type'], train_iter_params['batch_size'],encoder,decoder)\n        \n        print(\"Valid accuracy is \", valid_accuracy)\n        #when running sweeep \n        #wandb.log({\"validation_accuracy\": valid_accuracy, \"training_loss\": avg_loss})\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:38.485706Z","iopub.execute_input":"2023-05-19T07:50:38.486077Z","iopub.status.idle":"2023-05-19T07:50:38.501063Z","shell.execute_reply.started":"2023-05-19T07:50:38.486046Z","shell.execute_reply":"2023-05-19T07:50:38.499890Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder_obj, decoder_obj, input_tensors, cell_type,batch_size):\n    with torch.no_grad():\n        \n        predicted_word_tensor=[]\n        encoder_hidden = encoder_obj.initHidden()\n        \n        if (cell_type=='GRU' or cell_type=='RNN'):\n            encoder_output,encoder_hidden = encoder_obj(input_tensors, encoder_hidden)\n        else:\n            encoder_output,encoder_hidden, encoder_cell = encoder_obj(input_tensors, encoder_hidden)\n\n               \n\n        decoder_input = torch.tensor([SOW_token]*batch_size).to(device)  # SOW\n\n        decoder_hidden = encoder_hidden\n        if cell_type == \"LSTM\":\n            decoder_cell = encoder_cell\n               \n            \n        for i in range(input_tensors.size(0)):\n            \n            if(attention==False):\n                if cell_type == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell = decoder_obj(decoder_input, (decoder_hidden, decoder_cell))\n                else:\n                    decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden)\n                topv, topi = decoder_output.data.topk(1)\n            else:\n                if cell_type == \"LSTM\":\n                    decoder_output, decoder_hidden, decoder_cell,attn_weights = decoder_obj(decoder_input, (decoder_hidden, decoder_cell),encoder_output)\n                else:\n                    decoder_output, decoder_hidden,attn_weights = decoder_obj(decoder_input, decoder_hidden,encoder_output)\n                topv, topi = decoder_output.data.topk(1)\n                \n                \n                                    \n            temp=topi.view(1,-1).squeeze()\n            predicted_word_tensor.append(temp)\n            decoder_input = topi.squeeze().detach()\n            \n        predicted_word_tensor=torch.stack(predicted_word_tensor,dim=1).to(device)\n        \n        return predicted_word_tensor\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:39.211664Z","iopub.execute_input":"2023-05-19T07:50:39.212031Z","iopub.status.idle":"2023-05-19T07:50:39.223300Z","shell.execute_reply.started":"2023-05-19T07:50:39.212000Z","shell.execute_reply":"2023-05-19T07:50:39.222318Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cal_Accuracy(input, actual_output, cell_type, batch_size,encoder1,decoder1):\n    correct_output=0\n    no_of_batch=len(input)\n    no_of_datapoints=batch_size*no_of_batch \n    #incorrect_correct_pair=[]\n    #list_word_predicted=[]\n    \n    for i in range(no_of_batch):\n        output_tensor_predicted = evaluate(encoder1, decoder1, input[i], cell_type,batch_size)\n        #print(output_tensor_predicted.shape)\n                \n        for j in range(output_tensor_predicted.size(0)):\n            string=\"\"\n            for k in range(output_tensor_predicted.size(1)):\n                target_val=output_tensor_predicted[j][k].item()\n                if(target_val==EOW_token or target_val==PAD_token):\n                    break\n                else:\n                    string =string+output_word_dict.indextochar[target_val]\n            \n#             list_word_predicted.append(string)\n            if(actual_output[i*batch_size+j]==string):\n                correct_output+=1\n    \n    return (correct_output/no_of_datapoints *100)\n            \n  \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:40.414298Z","iopub.execute_input":"2023-05-19T07:50:40.415076Z","iopub.status.idle":"2023-05-19T07:50:40.423956Z","shell.execute_reply.started":"2023-05-19T07:50:40.415035Z","shell.execute_reply":"2023-05-19T07:50:40.422932Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"def cal_Accuracy_test(input, actual_output, cell_type, batch_size,encoder1,decoder1):\n    correct_output=0\n    no_of_batch=len(input)\n    no_of_datapoints=batch_size*no_of_batch \n    #incorrect_correct_pair=[]\n    list_word_predicted=[]\n    \n    for i in range(no_of_batch):\n        output_tensor_predicted = evaluate(encoder1, decoder1, input[i], cell_type,batch_size)\n        #print(output_tensor_predicted.shape)\n                \n        for j in range(output_tensor_predicted.size(0)):\n            string=\"\"\n            for k in range(output_tensor_predicted.size(1)):\n                target_val=output_tensor_predicted[j][k].item()\n                if(target_val==EOW_token or target_val==PAD_token):\n                    break\n                else:\n                    string =string+output_word_dict.indextochar[target_val]\n            \n            list_word_predicted.append(string)\n            if(actual_output[i*batch_size+j]==string):\n                correct_output+=1\n    \n    return (list_word_predicted,correct_output/no_of_datapoints *100)\n            \n  \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:42.689249Z","iopub.execute_input":"2023-05-19T07:50:42.689630Z","iopub.status.idle":"2023-05-19T07:50:42.700512Z","shell.execute_reply.started":"2023-05-19T07:50:42.689599Z","shell.execute_reply":"2023-05-19T07:50:42.699066Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"def getprediceted_list_test():\n    test_inputword_list=getlistofwords_x(test_dataset)\n    testinput_tensor_list=[]\n\n    for i in range(len(test_inputword_list)):\n        if(attention == False and i%paramet['batch_size']==0 ):\n            max_length_x=getlength_x(test_dataset[i:i+paramet['batch_size']])\n        elif(attention == True):\n            max_length_x=max_input_length\n\n        testinputwordtensor =tensorsFormation(test_inputword_list[i],max_length_x,input_word_dict)\n        testinput_tensor_list.append(testinputwordtensor)\n\n    test_batch_input = batchcreation(testinput_tensor_list, paramet['batch_size'])\n    test_output_list= getlistofwords_y(test_dataset)\n    list_word_predicted,test_accuracy = cal_Accuracy_test(test_batch_input, test_output_list, paramet['cell_type'], paramet['batch_size'],encodertest,decodertest)\n    print('test_accuracy is ',test_accuracy)\n    return list_word_predicted","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:43.430891Z","iopub.execute_input":"2023-05-19T07:50:43.431268Z","iopub.status.idle":"2023-05-19T07:50:43.438523Z","shell.execute_reply.started":"2023-05-19T07:50:43.431237Z","shell.execute_reply":"2023-05-19T07:50:43.437577Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"#to get the predicted list first with vanilla version then with attention then comapre what attention \n#predicted correct \nattention = True\nparamet= {\n\n\"input_size_encoder\":input_word_dict.n_chars,\n\"output_size_decoder\":output_word_dict.n_chars,\n\"hidden_size\":  512,\n\"num_layers\":  1,\n\"dropout_encoder\":0.4,\n\"dropout_decoder\": 0.2,\n\"batch_size\": 128,\n\"embedding_size\": 512,\n\"epochs\": 15,\n\"cell_type\":\"GRU\",\n\"bidirectional\": True\n    \n}\n\nencodertest = EncoderRNN(paramet).to(device)\nif(attention==False):\n    decodertest = DecoderRNN(paramet).to(device)\nelse:\n    decodertest=AttnDecoderRNN(paramet).to(device)\n    \n\ntrain_iter_params={\n    'epochs':paramet['epochs'],\n    'learning_rate':0.001,\n    'batch_size':paramet['batch_size'],\n    'cell_type':paramet['cell_type']  \n    \n    \n }\ntrain_setup(encodertest, decodertest, train_iter_params,paramet)\nlist_word_predicted_atten=getprediceted_list_test()\n\ntest_output_df = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',names=['input','output'])\ntest_output_df['predicted_output']=list_word_predicted_atten\ntest_output_df.to_csv('resultattention.csv')\n\n\n\n\nattention = False\n\nparamet= {\n\n\"input_size_encoder\":input_word_dict.n_chars,\n\"output_size_decoder\":output_word_dict.n_chars,\n\"hidden_size\":  512,\n\"num_layers\":  2,\n\"dropout_encoder\":0.4,\n\"dropout_decoder\": 0.3,\n\"batch_size\": 64,\n\"embedding_size\": 512,\n\"epochs\": 10,\n\"cell_type\":\"LSTM\",\n\"bidirectional\": True\n    \n}\n\nencodertest = EncoderRNN(paramet).to(device)\nif(attention==False):\n    decodertest = DecoderRNN(paramet).to(device)\nelse:\n    decodertest=AttnDecoderRNN(paramet).to(device)\n    \n\ntrain_iter_params={\n    'epochs':paramet['epochs'],\n    'learning_rate':0.001,\n    'batch_size':paramet['batch_size'],\n    'cell_type':paramet['cell_type']  \n    \n    \n }\ntrain_setup(encodertest, decodertest, train_iter_params,paramet)\nlist_word_predicted_vanilla=getprediceted_list_test()\n\ntest_output_df = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',names=['input','output'])\ntest_output_df['predicted_output']=list_word_predicted_vanilla\ntest_output_df.to_csv('resultvanilla.csv')\n\n    \ntest_actual_output=getlistofwords_y(test_dataset)\ncount_corrected_pre=0\nfor i in range(len(test_actual_output)):\n    if(test_actual_output[i]==list_word_predicted_atten[i] and test_actual_output[i]!=list_word_predicted_vanilla[i]):\n        print('actual output is ',test_actual_output[i])\n        print('converted output using attention ',list_word_predicted_atten[i])\n        print('converted output without attention ',list_word_predicted_vanilla[i])\n        print('-------------------------------------------------------------------')\n        count_corrected_pre+=1\n        if(count_corrected_pre==5):\n            break\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:44.155599Z","iopub.execute_input":"2023-05-19T07:50:44.155990Z","iopub.status.idle":"2023-05-19T08:05:01.851480Z","shell.execute_reply.started":"2023-05-19T07:50:44.155961Z","shell.execute_reply":"2023-05-19T08:05:01.850198Z"},"trusted":true},"execution_count":208,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"epoch count is  1\naverage loss at   1 epochs is  1.1789383610978772\nValid accuracy is  23.8525390625\nepoch count is  2\naverage loss at   2 epochs is  0.5418024903719869\nValid accuracy is  31.298828125\nepoch count is  3\naverage loss at   3 epochs is  0.4400207104249904\nValid accuracy is  33.642578125\nepoch count is  4\naverage loss at   4 epochs is  0.4100514598396364\nValid accuracy is  34.7412109375\nepoch count is  5\naverage loss at   5 epochs is  0.40087428461479774\nValid accuracy is  36.0107421875\nepoch count is  6\naverage loss at   6 epochs is  0.3837528674047855\nValid accuracy is  36.3037109375\nepoch count is  7\naverage loss at   7 epochs is  0.35930055634363706\nValid accuracy is  37.841796875\nepoch count is  8\naverage loss at   8 epochs is  0.33032367202371254\nValid accuracy is  38.232421875\nepoch count is  9\naverage loss at   9 epochs is  0.3192617187894774\nValid accuracy is  39.4287109375\nepoch count is  10\naverage loss at   10 epochs is  0.3173701284734204\nValid accuracy is  39.8681640625\nepoch count is  11\naverage loss at   11 epochs is  0.3117215256899977\nValid accuracy is  38.525390625\nepoch count is  12\naverage loss at   12 epochs is  0.3198050605438228\nValid accuracy is  37.8173828125\nepoch count is  13\naverage loss at   13 epochs is  0.27523516426813727\nValid accuracy is  38.0615234375\nepoch count is  14\naverage loss at   14 epochs is  0.27565796941518067\nValid accuracy is  38.7939453125\nepoch count is  15\naverage loss at   15 epochs is  0.26616515356720777\nValid accuracy is  38.7939453125\n37.6953125\nepoch count is  1\naverage loss at   1 epochs is  0.9108894463992104\nValid accuracy is  20.41015625\nepoch count is  2\naverage loss at   2 epochs is  0.5778770055931878\nValid accuracy is  27.7587890625\nepoch count is  3\naverage loss at   3 epochs is  0.5197754852844715\nValid accuracy is  30.4443359375\nepoch count is  4\naverage loss at   4 epochs is  0.48262125709977943\nValid accuracy is  30.4931640625\nepoch count is  5\naverage loss at   5 epochs is  0.4470923224668414\nValid accuracy is  31.2255859375\nepoch count is  6\naverage loss at   6 epochs is  0.44249719086420847\nValid accuracy is  32.1044921875\nepoch count is  7\naverage loss at   7 epochs is  0.41653193078247946\nValid accuracy is  31.9091796875\nepoch count is  8\naverage loss at   8 epochs is  0.4056582839029237\nValid accuracy is  33.1787109375\nepoch count is  9\naverage loss at   9 epochs is  0.385453980968303\nValid accuracy is  32.958984375\nepoch count is  10\naverage loss at   10 epochs is  0.3758626581071169\nValid accuracy is  32.8369140625\n31.787109375\nactual output is  इंडिपेंडेंस\nconverted output using attention  इंडिपेंडेंस\nconverted output without attention  इंडीपेंडेंस\n-------------------------------------------------------------------\nactual output is  हाशिए\nconverted output using attention  हाशिए\nconverted output without attention  हाशी\n-------------------------------------------------------------------\nactual output is  फूहड़ता\nconverted output using attention  फूहड़ता\nconverted output without attention  फूहद्ता\n-------------------------------------------------------------------\nactual output is  इक़बाल\nconverted output using attention  इक़बाल\nconverted output without attention  इक्बाल\n-------------------------------------------------------------------\nactual output is  फर्रूखनगर\nconverted output using attention  फर्रूखनगर\nconverted output without attention  फर्रूख्णरग\n-------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# paramet= {\n\n# \"input_size_encoder\":input_word_dict.n_chars,\n# \"output_size_decoder\":output_word_dict.n_chars,\n# \"hidden_size\":  512,\n# \"num_layers\":  2,\n# \"dropout_encoder\":0.4,\n# \"dropout_decoder\": 0.3,\n# \"batch_size\": 64,\n# \"embedding_size\": 512,\n# \"epochs\": 10,\n# \"cell_type\":\"LSTM\",\n# \"bidirectional\": True\n    \n# }","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:05:01.853868Z","iopub.execute_input":"2023-05-19T08:05:01.854315Z","iopub.status.idle":"2023-05-19T08:05:01.860245Z","shell.execute_reply.started":"2023-05-19T08:05:01.854272Z","shell.execute_reply":"2023-05-19T08:05:01.859217Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"# encodertest = EncoderRNN(paramet).to(device)\n# if(attention==False):\n#     decodertest = DecoderRNN(paramet).to(device)\n# else:\n#     decodertest=AttnDecoderRNN(paramet).to(device)\n    \n\n# train_iter_params={\n#     'epochs':paramet['epochs'],\n#     'learning_rate':0.001,\n#     'batch_size':paramet['batch_size'],\n#     'cell_type':paramet['cell_type']  \n    \n    \n#  }\n# train_setup(encodertest, decodertest, train_iter_params,paramet)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:06:34.986196Z","iopub.execute_input":"2023-05-19T07:06:34.986592Z","iopub.status.idle":"2023-05-19T07:13:17.708077Z","shell.execute_reply.started":"2023-05-19T07:06:34.986558Z","shell.execute_reply":"2023-05-19T07:13:17.706983Z"},"trusted":true},"execution_count":173,"outputs":[{"name":"stdout","text":"epoch count is  1\naverage loss at   1 epochs is  1.00620045134134\nValid accuracy is  25.78125\nepoch count is  2\naverage loss at   2 epochs is  0.5024777852100586\nValid accuracy is  31.7626953125\nepoch count is  3\naverage loss at   3 epochs is  0.43877922390554125\nValid accuracy is  34.1796875\nepoch count is  4\naverage loss at   4 epochs is  0.38649523156762283\nValid accuracy is  36.03515625\nepoch count is  5\naverage loss at   5 epochs is  0.37700234202074023\nValid accuracy is  37.4267578125\nepoch count is  6\naverage loss at   6 epochs is  0.36325877447474453\nValid accuracy is  37.451171875\nepoch count is  7\naverage loss at   7 epochs is  0.34135886038117086\nValid accuracy is  37.8662109375\nepoch count is  8\naverage loss at   8 epochs is  0.3397493875315884\nValid accuracy is  38.1591796875\nepoch count is  9\naverage loss at   9 epochs is  0.3268018930633557\nValid accuracy is  37.255859375\nepoch count is  10\naverage loss at   10 epochs is  0.3179253804590276\nValid accuracy is  36.6455078125\nepoch count is  11\naverage loss at   11 epochs is  0.2964524640414659\nValid accuracy is  39.2578125\nepoch count is  12\naverage loss at   12 epochs is  0.2907318541313532\nValid accuracy is  37.4755859375\nepoch count is  13\naverage loss at   13 epochs is  0.28787860386585246\nValid accuracy is  37.1826171875\nepoch count is  14\naverage loss at   14 epochs is  0.26415634962241585\nValid accuracy is  37.5\nepoch count is  15\naverage loss at   15 epochs is  0.2659353863455357\nValid accuracy is  39.84375\n","output_type":"stream"}]},{"cell_type":"code","source":"# #to see on test dataset \n# test_inputword_list=getlistofwords_x(test_dataset)\n# testinput_tensor_list=[]\n\n# for i in range(len(test_inputword_list)):\n#     if(attention == False and i%paramet['batch_size']==0 ):\n#         max_length_x=getlength_x(test_dataset[i:i+paramet['batch_size']])\n#     elif(attention == True):\n#         max_length_x=max_input_length\n\n#     testinputwordtensor =tensorsFormation(test_inputword_list[i],max_length_x,input_word_dict)\n#     testinput_tensor_list.append(testinputwordtensor)\n\n# test_batch_input = batchcreation(testinput_tensor_list, paramet['batch_size'])\n# test_output_list= getlistofwords_y(test_dataset)\n# list_word_predicted,test_accuracy = cal_Accuracy_test(test_batch_input, test_output_list, paramet['cell_type'], paramet['batch_size'],encodertest,decodertest)\n# print(test_accuracy)\n# #39.1357421875","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:50:16.213423Z","iopub.execute_input":"2023-05-19T06:50:16.213835Z","iopub.status.idle":"2023-05-19T06:50:18.068815Z","shell.execute_reply.started":"2023-05-19T06:50:16.213801Z","shell.execute_reply":"2023-05-19T06:50:18.067676Z"},"trusted":true},"execution_count":153,"outputs":[{"name":"stdout","text":"31.7138671875\n","output_type":"stream"}]},{"cell_type":"code","source":"# list_word_predicted_vanilla=getprediceted_list_test()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:56:24.945287Z","iopub.execute_input":"2023-05-19T06:56:24.946251Z","iopub.status.idle":"2023-05-19T06:56:24.951091Z","shell.execute_reply.started":"2023-05-19T06:56:24.946193Z","shell.execute_reply":"2023-05-19T06:56:24.949825Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"# # #to form csv file of the predicted letters \n# test_output_df = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv',names=['input','output'])\n# test_output_df['predicted_output']=list_word_predicted_vanilla\n# test_output_df.to_csv('resultvanilla2.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:56:56.789047Z","iopub.execute_input":"2023-05-19T06:56:56.789405Z","iopub.status.idle":"2023-05-19T06:56:56.822891Z","shell.execute_reply.started":"2023-05-19T06:56:56.789374Z","shell.execute_reply":"2023-05-19T06:56:56.821927Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"# to get the words which are corrected by attention ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def runsweep():\n#     config = None\n#     with wandb.init(config = config, entity = 'singhbhavesh999') as run:\n#         config = wandb.config\n#         run.name='hl_'+str(config.hidden_layer)+'_bs_'+str(config.batch_size)+'_ct_'+config.cell_type\n#         #run.name = \"EBS_{}_NL_{}_HL_{}_CellT_{}_BS_{}\".format(config.embedding_size, config.num_layers, config.hidden_layer, config.cell_type,config.batch_size)\n#         param = {\n\n#             \"input_size_encoder\":input_word_dict.n_chars,\n#             \"output_size_decoder\":output_word_dict.n_chars,\n#             \"hidden_size\":  wandb.config.hidden_layer,\n#             \"num_layers\":  wandb.config.num_layers,\n#             \"dropout_encoder\":wandb.config.dropout_encoder,\n#             \"dropout_decoder\": wandb.config.dropout_decoder,\n#             \"batch_size\": wandb.config.batch_size,\n#             \"embedding_size\": wandb.config.embedding_size,\n#             \"epochs\": wandb.config.epochs,\n#             \"cell_type\":wandb.config.cell_type,\n#             \"bidirectional\": wandb.config.bidirectional\n\n#         }\n        \n        \n        \n\n       \n#         encoder1 = EncoderRNN(param).to(device)\n#         if(attention==False):\n#             decoder1 = DecoderRNN(param).to(device)\n#         else:\n#             decoder1=AttnDecoderRNN(param).to(device)\n\n\n#         train_iter_params={\n#             'epochs':param['epochs'],\n#             'learning_rate':0.001,\n#             'batch_size':param['batch_size'],\n#             'cell_type':param['cell_type']  \n#             }\n\n#         train_setup(encoder1, decoder1, train_iter_params,param)\n\n \n\n# wandb.agent(sweep_id, runsweep, count = 2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T20:26:15.481457Z","iopub.execute_input":"2023-05-18T20:26:15.482589Z","iopub.status.idle":"2023-05-18T20:37:48.909115Z","shell.execute_reply.started":"2023-05-18T20:26:15.482545Z","shell.execute_reply":"2023-05-18T20:37:48.908181Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6ziz1j0b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_decoder: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_encoder: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230518_202618-6ziz1j0b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m020/Assignment3/runs/6ziz1j0b' target=\"_blank\">peachy-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m020/Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m020/Assignment3/sweeps/a1yl77pu' target=\"_blank\">https://wandb.ai/cs22m020/Assignment3/sweeps/a1yl77pu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m020/Assignment3' target=\"_blank\">https://wandb.ai/cs22m020/Assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m020/Assignment3/sweeps/a1yl77pu' target=\"_blank\">https://wandb.ai/cs22m020/Assignment3/sweeps/a1yl77pu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m020/Assignment3/runs/6ziz1j0b' target=\"_blank\">https://wandb.ai/cs22m020/Assignment3/runs/6ziz1j0b</a>"},"metadata":{}},{"name":"stdout","text":"epoch count is  1\naverage loss at   1 epochs is  1.225223551959046\nValid accuracy is  11.9384765625\nepoch count is  2\naverage loss at   2 epochs is  0.7057481039882307\nValid accuracy is  20.6787109375\nepoch count is  3\naverage loss at   3 epochs is  0.6063149021120399\nValid accuracy is  23.779296875\nepoch count is  4\naverage loss at   4 epochs is  0.5509449524803557\nValid accuracy is  26.0009765625\nepoch count is  5\naverage loss at   5 epochs is  0.5083218414774848\nValid accuracy is  28.271484375\nepoch count is  6\naverage loss at   6 epochs is  0.4741551306824455\nValid accuracy is  30.5908203125\nepoch count is  7\naverage loss at   7 epochs is  0.4692886567389637\nValid accuracy is  31.591796875\nepoch count is  8\naverage loss at   8 epochs is  0.44553230925288867\nValid accuracy is  32.2509765625\nepoch count is  9\naverage loss at   9 epochs is  0.43833090340021835\nValid accuracy is  32.2998046875\nepoch count is  10\naverage loss at   10 epochs is  0.420538055465469\nValid accuracy is  33.7646484375\nepoch count is  11\naverage loss at   11 epochs is  0.4092702511217128\nValid accuracy is  32.7392578125\nepoch count is  12\naverage loss at   12 epochs is  0.39824306515132235\nValid accuracy is  33.984375\nepoch count is  13\naverage loss at   13 epochs is  0.3911715887737309\nValid accuracy is  34.521484375\nepoch count is  14\naverage loss at   14 epochs is  0.37619652724457914\nValid accuracy is  34.1064453125\nepoch count is  15\naverage loss at   15 epochs is  0.37143508234560874\nValid accuracy is  33.9599609375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▅▅▆▇▇▇▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_loss</td><td>0.37144</td></tr><tr><td>validation_accuracy</td><td>33.95996</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peachy-sweep-1</strong> at: <a href='https://wandb.ai/cs22m020/Assignment3/runs/6ziz1j0b' target=\"_blank\">https://wandb.ai/cs22m020/Assignment3/runs/6ziz1j0b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230518_202618-6ziz1j0b/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# wandb.agent('a0km7f3z', runSweep, count = 2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T17:12:18.638854Z","iopub.status.idle":"2023-05-18T17:12:18.639646Z","shell.execute_reply.started":"2023-05-18T17:12:18.639408Z","shell.execute_reply":"2023-05-18T17:12:18.639431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}